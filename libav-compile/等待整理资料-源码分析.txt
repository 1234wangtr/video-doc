计划：
 2014.10.14 【计划】《libav基础框架》
 2014.10.14 【计划】《理解：--enable-runtime-cpudetect》
 --enable-runtime-cpudetect detect cpu capabilities at runtime (bigger binary)
 #define CONFIG_RUNTIME_CPUDETECT 1
 config.asm
 
2014.10.14 【计划】下面参数分析
  --enable-gray            enable full grayscale support (slower color)
  --disable-swscale-alpha  disable alpha channel support in swscale
  Hardware accelerators:
  --enable-dxva2           enable DXVA2 code
  --enable-vaapi           enable VAAPI code
  --enable-vda             enable VDA code
  --enable-vdpau           enable VDPAU code
  
2014.10.14 【计划】《avlog, 是什么机制？》




AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA, AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA, 按照字节序来命名的




avcodec_open2 libavcodec\utils.c
options   参数：A dictionary filled with AVCodecContext and codec-private options. On return this object will be filled with options that were not found

avcodec_register_all();
av_dict_set(&opts, "b", "2.5M", 0);
codec = avcodec_find_decoder(AV_CODEC_ID_H264);
if (!codec)
    exit(1);

context = avcodec_alloc_context3(codec);

if (avcodec_open2(context, codec, opts) < 0)
    exit(1);
	
	
		AVCodecContext 对应的 字典（字段）
	
	
	
	ctx->priv_data  （X264Context）
	AVCodecContext  priv_data字段
	
	
	av_dict_get  av_dict_free av_dict_set
	
	
	av_free_packet 解码与编码时的用法
E:\libav101\libavcodec\avpacket.c

av_read_frame 会释放，传入的PKT吗？
av_interleaved_write_frame 会释放与完的PKT吗？

they explain that the packet doesn't always own the data it   
points to.

AVPacket结构本身只是个容器，它使用data成员指向实际的数据缓冲区，这个缓冲区可以通过av_new_packet创建，可以通过av_dup_packet拷贝，也可以由FFMPEG的API产生（如av_read_frame），使用之后需要通过调用av_free_packet释放。

av_free_packet调用的是结构体本身的destruct函数，它的值有两种情况：
1)av_destruct_packet_nofree或0；
2)av_destruct_packet，

其中，前者仅仅是将data和size的值清0而已，后者才会真正地释放缓冲区。

FFMPEG内部使用AVPacket结构建立缓冲区装载数据，
同时提供destruct函数，
如果FFMPEG打算自己维护缓冲区，
则将destruct设为av_destruct_packet_nofree，
用户调用av_free_packet清理缓冲区时并不能够将其释放；

如果FFMPEG不会再使用该缓冲区，则将destruct设为av_destruct_packet，表示它能够被释放。
对于缓冲区不能够被释放的AVPackt，用户在使用之前最好调用av_dup_packet进行缓冲区的克隆，将其转化为缓冲区能够被释放的AVPacket，以免对缓冲区的不当占用造成异常错误。

而av_dup_packet会为destruct指针为av_destruct_packet_nofree的AVPacket新建一个缓冲区，然后将原缓冲区的数据拷贝至新缓冲区，置data的值为新缓冲区的地址，同时设destruct指针为av_destruct_packet











libavutil/float_dsp.c
http://blog.csdn.net/ganxingming/article/details/1449526

http://baike.baidu.com/subview/162096/5142229.htm?fromtitle=dsp&fromid=74514&type=syn
简单地说，数字信号处理就是用数值计算的方式对信号进行加工的理论和技术，它的英文原名叫digital signal processing，简称DSP。另外DSP也是digital signal processor的简称，即数字信号处理器，它是集成专用计算机的一种芯片，只有一枚硬币那么大。有时人们也将DSP看作是一门应用技术，称为DSP技术与应用

DSP是digital signal processor的简称，即数字信号处理器，广泛运用于嵌入式系统中。它是集成专用计算机的一种芯片，只有一枚硬币那么大。有时人们也将DSP看作是一门应用技术，称为DSP技术和应用


http://www.dataphysics.com/zh/products-and-solutions/vibration-controllers-signalstar/signalstar-scalar.html
32位浮点数数字信号处理器

http://book.douban.com/subject/3999037/
DSP就是，数字信号处理器的意思。

http://zh.wikipedia.org/wiki/%E7%9F%A2%E9%87%8F
http://blog.csdn.net/tina_lulu_21/article/details/2460833
Scalar Multiplication （纯量乘法）
Matrix multiplication（矩阵乘法）

http://www.baike.com/wiki/%E3%80%8ADSP%E7%AE%97%E6%B3%95%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AE%9E%E7%8E%B0%E6%8A%80%E6%9C%AF%E3%80%8B
DSP算法与体系结构实现技术

http://aquila-dsp.org/
Aquila is an open source and cross-platform DSP (Digital Signal Processing) library written in C++





Various input signal sources
Windowing and filtering
FFT-related transformations
Feature extraction (including MFCC and HFCC)
Pattern matching using Dynamic Time Warping (DTW)



avstream avg_frame_rate 参数计算方法
1. 读几帧，计算平均值
2. time_scale * nb_frames / duration


计算每一帧图片的显示时间
AVFrame::pts
AVFrame::pkt_pts


VFR CFR
variable frame rate
constant frame rate












AVFilter
#if CONFIG_AVFILTER
# include "libavfilter/avfilter.h"
# include "libavfilter/buffersink.h"
# include "libavfilter/buffersrc.h"
#endif

avfilter_register_all();

    av_freep(&vfilters);
    avfilter_graph_free(&graph);  会调用，request_frame，一直调用所有的FILTER

输入、输出，接口。
ret = av_buffersrc_add_frame(filt_in, frame);
ret = av_buffersink_get_frame(filt_out, frame);

1. avfiilter 可以完成所有SwsContext实现的功能 
    仅仅是做图像的pixel format处理,用libswscale是相当简单
    libavfilter.使用它,可以完全代替libswscale,
    并且可以自动完成一些复杂的转换操作

2. 
    AVFilterContext *in_video_filter;   
              // the first filter in the video chain
    AVFilterContext *out_video_filter;  
             // the last filter in the video chain

static char *vfilters = NULL;（filter字符串）

3.    视频从FILTER处理后的，长宽等等参数
        w = is->out_video_filter->inputs[0]->w;
        h = is->out_video_filter->inputs[0]->h;

    vp->width   = is->out_video_filter->inputs[0]->w;
    vp->height  = is->out_video_filter->inputs[0]->h;
    vp->pix_fmt = is->out_video_filter->inputs[0]->format;

4. 创建Filter，配置FilterGraph(最复杂的部分)
    buffer 和 buffersink 两个FILTER，是最重要的。

buffer
Buffer video frames, and make them accessible to the filterchain.

buffersink
Buffer video frames, and make them available to the end of the filter graph.





reference-counted data buffers 
av_frame_ref
av_frame_unref

Libav 10 是重要的一个特性：
One of the main features of this release is the addition of reference-counted data buffers to Libav and their use in various structures

av_packet_ref  and  av_packet_unref replace the usage of av_dup_packet.

av_frame_free / av_free_packet 与
av_frame_unref  /  av_packet_unref  怎么使用？









av_rescale_q
rational number : 整数和分数统称为有理数

有理数集可用大写黑正体符号Q代表 
但Q绝对不表示有理数。因为有理数集与有理数是两个不同的概念。有理数集是元素为全体有理数的集合，而有理数则为有理数集中的所有元素

int64_t av_rescale_q (int64_t a, AVRational bq, AVRational cq) av_const

a * bq / cq









AV_TIME_BASE and AV_TIME_BASE_Q
不要使用这两个宏
Now you should use the av_time_base() and av_time_base_q() accessors

Now you should use the av_time_base() and av_time_base_q() accessors









Libav 硬件加速用法 libavcodec/allcodecs.c
见avconv.c里面的：
    /* hwaccel options */
    enum HWAccelID hwaccel_id;
    char  *hwaccel_device;

    /* hwaccel context */
    enum HWAccelID active_hwaccel_id;
    void  *hwaccel_ctx;
    void (*hwaccel_uninit)(AVCodecContext *s);
    int  (*hwaccel_get_buffer)(AVCodecContext *s, AVFrame *frame, int flags);
    int  (*hwaccel_retrieve_data)(AVCodecContext *s, AVFrame *frame);
    enum AVPixelFormat hwaccel_pix_fmt;
    enum AVPixelFormat hwaccel_retrieved_pix_fmt;
} InputStream;

struct AVHWAccel* AVCodecContext::hwaccel
void*                                 AVCodecContext::hwaccel_context   

AVHWAccel ff_h264_dxva2_hwaccel = {
    .name           = "h264_dxva2",
    .type           = AVMEDIA_TYPE_VIDEO,
    .id             = AV_CODEC_ID_H264,
    .pix_fmt        = AV_PIX_FMT_DXVA2_VLD,
    .start_frame    = dxva2_h264_start_frame,
    .decode_slice   = dxva2_h264_decode_slice,
    .end_frame      = dxva2_h264_end_frame,
    .priv_data_size = sizeof(struct dxva2_picture_context),
};

/* hardware accelerators */
    REGISTER_HWACCEL(H263_VAAPI,        h263_vaapi);
    REGISTER_HWACCEL(H263_VDPAU,        h263_vdpau);
    REGISTER_HWACCEL(H264_DXVA2,        h264_dxva2);
    REGISTER_HWACCEL(H264_VAAPI,        h264_vaapi);
    REGISTER_HWACCEL(H264_VDA,          h264_vda);
    REGISTER_HWACCEL(H264_VDPAU,        h264_vdpau);
    REGISTER_HWACCEL(MPEG1_VDPAU,       mpeg1_vdpau);
    REGISTER_HWACCEL(MPEG2_DXVA2,       mpeg2_dxva2);
    REGISTER_HWACCEL(MPEG2_VAAPI,       mpeg2_vaapi);
    REGISTER_HWACCEL(MPEG2_VDPAU,       mpeg2_vdpau);
    REGISTER_HWACCEL(MPEG4_VAAPI,       mpeg4_vaapi);
    REGISTER_HWACCEL(MPEG4_VDPAU,       mpeg4_vdpau);
    REGISTER_HWACCEL(VC1_DXVA2,         vc1_dxva2);
    REGISTER_HWACCEL(VC1_VAAPI,         vc1_vaapi);
    REGISTER_HWACCEL(VC1_VDPAU,         vc1_vdpau);
    REGISTER_HWACCEL(WMV3_DXVA2,        wmv3_dxva2);
    REGISTER_HWACCEL(WMV3_VAAPI,        wmv3_vaapi);
    REGISTER_HWACCEL(WMV3_VDPAU,        wmv3_vdpau);
	
	
	
		
		guess_correct_pts
		decoded_frame->pts = guess_correct_pts(&ist->pts_ctx, decoded_frame->pkt_pts,
                                           decoded_frame->pkt_dts);

cmdutils.c
int64_t guess_correct_pts(PtsCorrectionContext *ctx, int64_t reordered_pts,
                          int64_t dts)
{
    int64_t pts = AV_NOPTS_VALUE;

    if (dts != AV_NOPTS_VALUE) {
        ctx->num_faulty_dts += dts <= ctx->last_dts;
        ctx->last_dts = dts;
    }
    if (reordered_pts != AV_NOPTS_VALUE) {
        ctx->num_faulty_pts += reordered_pts <= ctx->last_pts;
        ctx->last_pts = reordered_pts;
    }
    if ((ctx->num_faulty_pts<=ctx->num_faulty_dts || dts == AV_NOPTS_VALUE)
        && reordered_pts != AV_NOPTS_VALUE)
        pts = reordered_pts;
    else
        pts = dts;

    return pts;
}

typedef struct PtsCorrectionContext {
    int64_t num_faulty_pts; /// Number of incorrect PTS values so far
    int64_t num_faulty_dts; /// Number of incorrect DTS values so far
    int64_t last_pts;       /// PTS of the last frame
    int64_t last_dts;       /// DTS of the last frame
} PtsCorrectionContext;


从文件读取来后，时间参数的，修正
1）ifile->ts_offset
2）ist->ts_scale
3）AVFMT_TS_DISCONT （时间，不连续）

    if (pkt.dts != AV_NOPTS_VALUE)
        pkt.dts += av_rescale_q(ifile->ts_offset, AV_TIME_BASE_Q, ist->st->time_base);
    if (pkt.pts != AV_NOPTS_VALUE)
        pkt.pts += av_rescale_q(ifile->ts_offset, AV_TIME_BASE_Q, ist->st->time_base);

    if (pkt.pts != AV_NOPTS_VALUE)
        pkt.pts *= ist->ts_scale;
    if (pkt.dts != AV_NOPTS_VALUE)
        pkt.dts *= ist->ts_scale;

    if (pkt.dts != AV_NOPTS_VALUE && ist->next_dts != AV_NOPTS_VALUE &&
        (is->iformat->flags & AVFMT_TS_DISCONT)) {
        int64_t pkt_dts = av_rescale_q(pkt.dts, ist->st->time_base, AV_TIME_BASE_Q);
        int64_t delta   = pkt_dts - ist->next_dts;

        if ((FFABS(delta) > 1LL * dts_delta_threshold * AV_TIME_BASE || pkt_dts + 1 < ist->last_dts) && !copy_ts) {
            ifile->ts_offset -= delta;
            av_log(NULL, AV_LOG_DEBUG,
                   "timestamp discontinuity %"PRId64", new offset= %"PRId64"\n",
                   delta, ifile->ts_offset);
            pkt.dts -= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);
            if (pkt.pts != AV_NOPTS_VALUE)
                pkt.pts -= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);
        }
    }
	
	
	
	
	
		
	AVRational 错误用法
	            video_out_frame_pts_= av_rescale_q(video_out_frame_index_ + 1,
                                               AVRational(1, video_output_fps_),
                                               AV_TIME_BASE_Q);

av_rescale_q 找不到声明。
#include <libavutil/mathematics.h>

AVRational(1, video_output_fps_)  这样写是错误的。
(AVRational){1, video_output_fps_}

链接时，找不到，av_resale_q，函数
extern "C" {
#include <libavutil/mathematics.h>
}







  
  zlib bzip2
  FFmpeg：以zlib读写Matroska等以DEFLATE算法压缩的多媒体串流格式。
  
  
  
  
  
  
  
  
  
libav zlib之间的关系
1.  libav 在那里用到了，这个库？ (CONFIG_ZLIB)

2.  同时使用还是，只使用一个？（要看，视频文件，里的某些压缩数据，使用了那种压缩算法）
FFmpeg：以zlib读写Matroska等以DEFLATE算法压缩的多媒体串流格式

3.  如果没有，会有什么替代方法？(有些解码器用到，且无替代方法，如)
E:\libav\libavformat\rtmpproto.c 下面代码：

#if CONFIG_ZLIB
        if ((ret = rtmp_uncompress_swfplayer(in_data + 8, in_size - 8,
                                             &out_data, &out_size)) < 0)
            goto fail;
#else
        av_log(s, AV_LOG_ERROR,
               "Zlib is required for decompressing the SWF player file.\n");
        ret = AVERROR(EINVAL);
        goto fail;
#endif


libavcodec/lclenc.c
LCL (LossLess Codec Library) Video Codec

AVCodec ff_zlib_encoder = {
    .name           = "zlib",
    .long_name      = NULL_IF_CONFIG_SMALL("LCL (LossLess Codec Library) ZLIB"),
    .type           = AVMEDIA_TYPE_VIDEO,
    .id             = AV_CODEC_ID_ZLIB,
    .priv_data_size = sizeof(LclEncContext),
    .init           = encode_init,
    .encode2        = encode_frame,
    .close          = encode_end,
    .pix_fmts       = (const enum AVPixelFormat[]) { AV_PIX_FMT_BGR24, AV_PIX_FMT_NONE },
};

#if CONFIG_MSZH_DECODER
AVCodec ff_mszh_decoder = {
    .name           = "mszh",
    .long_name      = NULL_IF_CONFIG_SMALL("LCL (LossLess Codec Library) MSZH"),
    .type           = AVMEDIA_TYPE_VIDEO,
    .id             = AV_CODEC_ID_MSZH,
    .priv_data_size = sizeof(LclDecContext),
    .init           = decode_init,
    .close          = decode_end,
    .decode         = decode_frame,
    .capabilities   = CODEC_CAP_DR1,
};
#endif

#if CONFIG_ZLIB_DECODER
AVCodec ff_zlib_decoder = {
    .name           = "zlib",
    .long_name      = NULL_IF_CONFIG_SMALL("LCL (LossLess Codec Library) ZLIB"),
    .type           = AVMEDIA_TYPE_VIDEO,
    .id             = AV_CODEC_ID_ZLIB,
    .priv_data_size = sizeof(LclDecContext),
    .init           = decode_init,
    .close          = decode_end,
    .decode         = decode_frame,
    .capabilities   = CODEC_CAP_DR1,
};
#endif








libav bzip2 之间的关系
只用在下面这个，demuxer里：
E:\libav\libavformat\matroskadec.c

#if CONFIG_ZLIB
#include <zlib.h>
#endif
#if CONFIG_BZLIB
#include <bzlib.h>
#endif










libav 三种压缩算法
#if CONFIG_ZLIB
                 encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_ZLIB &&
#endif
#if CONFIG_BZLIB
                 encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_BZLIB &&
#endif
#if CONFIG_LZO
                 encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_LZO &&
#endif








libav 有些函数，线程不安全
This function is not thread safe!
int avcodec_open2(AVCodecContext * avctx,const AVCodec * codec,AVDictionary ** options )

碰到一个问题
多线程调用avcodec_open2，avcodec_close
出现一个，avcodec_open2，或者，avformat_find_stream_info
得到的视频流的，pix_fmt，会被置成-1。








void *av_malloc(size_t size)
E:\libav101\libavutil\mem.c

CONFIG_MEMALIGN_HACK                 malloc(size + 32);
HAVE_POSIX_MEMALIGN                   posix_memalign(&ptr, 32, size)
HAVE_ALIGNED_MALLOC                  _aligned_malloc(size, 32);
HAVE_MEMALIGN                                    memalign(32, size);
                                                                               malloc(size)
																			   
																			   
																			   
																			   
																			   
																			   
																			   
																			   
																			   
																			   
																			   
																			   
avframe linesize 值分析 
480 x 480 的视频

解出一帧后，这个参数是：
linesize[0-2]: 512;256;256

而对于ＹＵＶ格式输出时，有三个通道可用，
即data[0][1][2],与linesize[0][1][2]，而yuv格式对于运动估计时，

需要填充padding(right, bottom),故：
linesize=width+padding size(16+16).

The linesize may be larger than the size of usable data – there may be extra padding present for performance reasons.

把YUV420P的，frame写到文件里的方法：

FILE *f = fopen("sdcard/f.yuv", "wb");
                if(f) {
                    LOGI("fopen(\"sdcard/f.yuv\", \"wb\") linesize[0-2]: %d;%d;%d", yuv_frame_->linesize[0], yuv_frame_->linesize[1], yuv_frame_->linesize[2]);
                    for(int i = 0; i < video_height_; i++) {
                        fwrite(yuv_frame_->data[0] + i * yuv_frame_->linesize[0], 1, video_width_, f);
                    }
                    for(int i = 0; i < video_height_ / 2; i++) {
                        fwrite(yuv_frame_->data[1] + i * yuv_frame_->linesize[1], 1, video_width_ / 2, f);
                    }
                    for(int i = 0; i < video_height_ / 2; i++) {
                        fwrite(yuv_frame_->data[2] + i * yuv_frame_->linesize[2], 1, video_width_ / 2, f);
                    }
                    fclose(f);
                }

				
				
				
				
				
				libav avframe data 里 可能有多余的填充数据。
				FILE *f = fopen("sdcard/f.yuv", "wb");
                if(f) {
                    LOGI("fopen(\"sdcard/f.yuv\", \"wb\") linesize[0-2]: %d;%d;%d", yuv_frame_->linesize[0], yuv_frame_->linesize[1], yuv_frame_->linesize[2]);
                    for(int i = 0; i < video_height_; i++) {
                        fwrite(yuv_frame_->data[0] + i * yuv_frame_->linesize[0], video_width_, 1, f);
                    }
                    for(int i = 0; i < video_height_ / 2; i++) {
                        fwrite(yuv_frame_->data[1] + i * yuv_frame_->linesize[1], 1, video_width_ / 2, f);
                    }
                    for(int i = 0; i < video_height_ / 2; i++) {
                        fwrite(yuv_frame_->data[2] + i * yuv_frame_->linesize[2], 1, video_width_ / 2, f);
                    }
                    fclose(f);
                }
				
				
				
				
				
				
				
				
				
				
				
				
				
				
				h264 Chroma formats libav
				Support of monochrome (4:0:0), 4:2:0, 4:2:2, and 4:4:4 chroma subsampling (depending on the selected profile).

libav AVFrame NV12 / NV21
AV_PIX_FMT_NV12 
planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V)

AV_PIX_FMT_NV21 
as above, but U and V bytes are swapped

AVFrame::data   AVFrame::linesize
// 2 planes for NV12: Y and interleaved UV
uint8_t * data[2] = {Y, Y + Stride * Height}; 

// Strides for Y and UV
// U and V have Stride/2 bytes per line; 
// Thus, we have 2 * Stride/2 bytes per line in UV plane
int linesize[2] = {Stride, Stride}; 

uint8_t * outData[1] = {out}; // RGB have one plane 
int outLinesize[1] = {frameWidth*4}; // RGB32 Stride

sws_scale(context, data, linesize, 0, Height, outData, outLinesize);









avcodec_open2 
AVDictionary *option = 0;
    ret = avcodec_open2(video_decoder_ctx_, video_decoder, &option);

为什么，最后一个值必须要，不能传空？










void avformat_close_input(AVFormatContext ** s)
Close an opened input AVFormatContext.
Free it and all its contents and set *s to NULL.







void av_frame_free(AVFrame ** frame)
Free the frame and any dynamically allocated objects in it, e.g.
extended_data. If the frame is reference counted, it will be unreferenced first.

frameframe to be freed. The pointer will be set to NULL.







int avcodec_close(AVCodecContext * avctx)
Close a given AVCodecContext and free all the data associated with it
 (but not the AVCodecContext itself).

Calling this function on an AVCodecContext that hasn't been opened 
will 
free the codec-specific data allocated 
in avcodec_alloc_context3() /avcodec_get_context_defaults3() 
with a non-NULL codec. 

Subsequent calls will do nothing.






AVFrame pts  pkt_pts  pkt_dts
int64_t pts Presentation timestamp in time_base units (time when frame should be shown to user). 
int64_t pkt_pts PTS copied from the AVPacket that was decoded to produce this frame. 
int64_t pkt_dts DTS copied from the AVPacket that triggered returning this frame. 

解码一个视频文件，发现 AVFrame->pts 始终为











libav 声音解码 并 重采样
avcodec_decode_audio4(audio_decoder_ctx_, audio_frame_src_, &got_frame, &media_data_pkt_);

AVFrame *audio_frame_src_;
AVFrame *audio_frame_s16_;

        audio_frame_src_ = av_frame_alloc();
        audio_frame_s16_ = av_frame_alloc();

nb_samples = avresample_convert(audio_resample_ctx_,
                                                audio_frame_s16_->data,
                                                audio_frame_s16_->linesize[0],
                                                audio_frame_s16_->nb_samples,
                                                audio_frame_src_->data,
                                                audio_frame_src_->linesize[0],
                                                audio_frame_src_->nb_samples);


分配，配置声音重采样上下文，AVAudioResampleContext 

            audio_resample_ctx_ = avresample_alloc_context();
            av_opt_set_int(audio_resample_ctx_, "in_channel_layout", av_get_default_channel_layout(audio_nb_channels_), 0);
            av_opt_set_int(audio_resample_ctx_, "out_channel_layout", av_get_default_channel_layout(audio_des_sample_nb_channels_), 0);
            av_opt_set_int(audio_resample_ctx_, "in_sample_rate", audio_sample_rate_, 0);
            av_opt_set_int(audio_resample_ctx_, "out_sample_rate", audio_des_sample_rate_, 0);
            av_opt_set_int(audio_resample_ctx_, "in_sample_fmt", audio_src_sample_fmt_, 0);
            av_opt_set_int(audio_resample_ctx_, "out_sample_fmt", audio_des_sample_fmt_, 0);
            avresample_open(audio_resample_ctx_);
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			libav make: error C2059: 语法错误:“sizeof"
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
avcodec_encode_audio2 -22
int ret = avcodec_encode_audio2(audio_encoder_ctx_, &pkt, audio_frame_, &got_packet);

mp3 frame_size == 1152
aac frame_size == 1024

convert mp3 to aac 时，这里avcodec_encode_audio2出错了。

解决方法：FIFO


